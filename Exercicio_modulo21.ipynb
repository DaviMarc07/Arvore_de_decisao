{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6588bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 1. Dados Fictícios de Exemplo (Substitua pela sua base do M17/M20) ---\n",
    "# Usarei uma base representativa para que o código seja executável.\n",
    "data = {\n",
    "    'Age': np.random.randint(20, 60, 100),\n",
    "    'Gender': np.random.choice(['Male', 'Female'], 100),\n",
    "    'Income': np.random.randint(30000, 150000, 100),\n",
    "    'Education': np.random.choice([\"Bachelor's Degree\", \"Master's Degree\", \"Doctorate\"], 100),\n",
    "    'Marital_Status': np.random.choice(['Single', 'Married'], 100),\n",
    "    'Number_of_Children': np.random.randint(0, 4, 100),\n",
    "    'Home_Ownership': np.random.choice(['Owned', 'Rented'], 100),\n",
    "    'Credit_Score': np.random.choice(['High', 'Average', 'Low'], 100, p=[0.7, 0.2, 0.1]) # Base desbalanceada\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pré-processamento e Encoding (Módulo 17/20)\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "colunas_categoricas = ['gender', 'education', 'marital_status', 'home_ownership']\n",
    "df_encoded = pd.get_dummies(df, columns=colunas_categoricas, drop_first=True)\n",
    "\n",
    "# Definição de X e y\n",
    "X = df_encoded.drop('credit_score', axis=1)\n",
    "y = df_encoded['credit_score']\n",
    "\n",
    "# Divisão do dataset (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Escalonamento dos dados (Regressão Logística é sensível à escala)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Balanceamento com SMOTE (Apenas na base de Treino)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanceado, y_train_balanceado = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Shape de Treino balanceado: {X_train_balanceado.shape}\")\n",
    "print(\"Contagem do Target Balanceado:\")\n",
    "print(y_train_balanceado.value_counts().to_markdown())\n",
    "\n",
    "# Instanciar o modelo de Regressão Logística (multinomial para lidar com 3 classes)\n",
    "# max_iter é aumentado para garantir convergência\n",
    "log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "\n",
    "# Treinar o modelo na base balanceada e escalonada\n",
    "log_reg.fit(X_train_balanceado, y_train_balanceado)\n",
    "\n",
    "# Fazer as previsões na base de TESTE (escalonada)\n",
    "y_pred_test = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(\"Modelo de Regressão Logística treinado e previsões realizadas com sucesso na base de Teste.\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Acurácia (Accuracy) na Base de Teste: {accuracy:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "labels = sorted(y_test.unique())\n",
    "\n",
    "print(\"Matriz de Confusão:\")\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(cm_df.to_markdown())\n",
    "\n",
    "# Visualização da Matriz de Confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='PuBu',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Matriz de Confusão (Regressão Logística)')\n",
    "plt.ylabel('Valores Reais')\n",
    "plt.xlabel('Previsões do Modelo')\n",
    "plt.show()\n",
    "\n",
    "report = classification_report(y_test, y_pred_test, output_dict=True, zero_division=0)\n",
    "report_df = pd.DataFrame(report).transpose().round(4)\n",
    "\n",
    "print(\"Relatório de Classificação (Precision, Recall, F1-Score, Support):\")\n",
    "print(report_df.to_markdown())\n",
    "\n",
    "# Acurácia por Classe (Precision) e Recall Médio (Média Ponderada)\n",
    "precision_macro = report_df.loc['macro avg', 'precision']\n",
    "recall_macro = report_df.loc['macro avg', 'recall']\n",
    "\n",
    "print(f\"\\nPrecision Médio (Macro Average): {precision_macro:.4f}\")\n",
    "print(f\"Recall Médio (Macro Average): {recall_macro:.4f}\")\n",
    "\n",
    "# Obter nomes das features (após o One-Hot Encoding)\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Obter classes (para Regressão Logística Multiclasse)\n",
    "classes = log_reg.classes_\n",
    "\n",
    "# Criar um DataFrame com os coeficientes\n",
    "# log_reg.coef_ tem shape (n_classes, n_features)\n",
    "coef_df = pd.DataFrame(log_reg.coef_, columns=feature_names, index=classes)\n",
    "\n",
    "print(\"--- Coeficientes do Modelo (Impacto das Features) ---\")\n",
    "print(\"Quanto maior o valor (em módulo), maior o impacto da feature na previsão da classe.\")\n",
    "print(coef_df.T.to_markdown())\n",
    "\n",
    "### Conclusão e Comparação de Desempenho\n",
    "\n",
    "**Comparação com Naive Bayes (Módulo 20):**\n",
    "\n",
    "A Regressão Logística geralmente oferece um desempenho mais equilibrado do que o Naive Bayes neste tipo de problema. Enquanto o Naive Bayes é mais rápido, ele sofre com a suposição de independência das *features*. A Regressão Logística, por ser mais robusta, tende a ter um **Recall e Precision mais altos** nas classes minoritárias ('Low' e 'Average'), que são cruciais para a gestão de risco.\n",
    "\n",
    "**Justificativa de Escolha:**\n",
    "\n",
    "A Regressão Logística é uma das melhores escolhas para o Credit Score porque:\n",
    "\n",
    "1.  **Alta Interpretabilidade:** Os coeficientes nos permitem entender **quais fatores (Renda, Idade, Educação)** e com qual **peso** estão influenciando a decisão do Score, fornecendo *insights* valiosos para o negócio.\n",
    "2.  **Saída Probabilística:** O modelo fornece a probabilidade de um cliente pertencer a cada classe (`High`, `Average`, `Low`), permitindo à instituição financeira definir um limite de risco mais flexível.\n",
    "3.  **Desempenho Estável:** Após o escalonamento e balanceamento, a Regressão Logística oferece um bom equilíbrio entre precisão geral e a capacidade de identificar corretamente as classes de alto e baixo risco."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
